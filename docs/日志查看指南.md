# 服务日志查看指南

当某个服务出现问题时，可以通过以下几种方式查看日志：

## 一、查看方式概览

根据你的论文和项目配置，系统使用了 **PLG Stack（Prometheus + Loki + Grafana）** 进行日志聚合。有以下三种查看日志的方式：

| 方式 | 适用场景 | 优点 | 缺点 |
|------|---------|------|------|
| **1. Grafana 可视化查询** | 生产环境、多服务排查 | 跨服务聚合、支持 TraceId 追踪、可视化好 | 需要启动 PLG 栈 |
| **2. 本地日志文件** | 开发环境、快速排查 | 简单直接、无需额外服务 | 无法跨服务聚合 |
| **3. Loki API 查询** | 自动化脚本、API 调用 | 可编程、支持复杂查询 | 需要熟悉 LogQL |

---

## 二、方式一：Grafana 可视化查询（推荐）

### 2.1 适用场景

- ✅ **多服务链路追踪**：一个请求经过 Gateway → KnowledgeService → FileService，需要查看完整链路
- ✅ **按 TraceId 追踪**：前端报错时提供 TraceId，快速定位问题
- ✅ **按时间范围查询**：查看特定时间段的错误日志
- ✅ **生产环境排查**：多个服务部署在不同机器

### 2.2 操作步骤

#### 步骤 1: 启动 PLG 监控栈

```bash
# 在项目根目录执行
docker compose up -d prometheus loki promtail grafana

# 验证服务是否启动
docker ps | grep -E "prometheus|loki|promtail|grafana"
```

#### 步骤 2: 访问 Grafana

- **URL**: http://localhost:3001
- **默认账号**: `admin`
- **默认密码**: `Zhz050108`（在 `docker-compose.yml` 中配置）

#### 步骤 3: 创建 Logs 面板

1. **进入 Explore 页面**
   - 点击左侧菜单的 **Explore**（指南针图标）

2. **选择 Loki 数据源**
   - 在顶部数据源下拉框中选择 **Loki**

3. **输入 LogQL 查询语句**

#### 2.3 常用查询示例

##### 查询特定服务的所有日志

```logql
# 查询 gateway-service 的所有日志
{container="knowledge-gateway"}

# 或者查询日志文件（如果使用文件日志）
{job="backend", filename="gateway-service.log"}
```

##### 查询错误日志

```logql
# 查询所有服务的错误日志
{job="backend"} |= "ERROR"

# 查询特定服务的错误日志
{container="knowledge-gateway"} |= "ERROR"

# 查询异常堆栈
{job="backend"} |~ "(?i)(exception|error|failed)"
```

##### 按 TraceId 追踪（重要！）

这是论文中提到的核心功能，可以跨服务追踪一个请求：

```logql
# 输入 TraceId 进行追踪（假设 TraceId 是 "a1b2c3d4"）
{job="backend"} |= "a1b2c3d4"

# 或者更精确的查询（如果 TraceId 在 MDC 中）
{job="backend"} | json | traceId="a1b2c3d4"
```

**使用场景**：
- 用户在前端报错："上传失败，TraceId: a1b2c3d4"
- 在 Grafana 中输入上述查询，可以看到该请求在所有服务中的完整日志链路：
  ```
  Gateway:    2024-01-01 10:00:01 [traceId=a1b2c3d4] INFO 接收上传请求
  FileService: 2024-01-01 10:00:01 [traceId=a1b2c3d4] INFO 开始上传分片
  FileService: 2024-01-01 10:00:02 [traceId=a1b2c3d4] ERROR 文件合并失败: OOM
  Gateway:    2024-01-01 10:00:02 [traceId=a1b2c3d4] ERROR 返回500错误
  ```

##### 查询特定时间范围的日志

```logql
# 查询最近 5 分钟的日志
{job="backend"} [5m]

# 查询最近 1 小时的错误日志
{job="backend"} |= "ERROR" [1h]
```

##### 查询包含特定关键词的日志

```logql
# 查询包含 "文件上传" 的日志
{job="backend"} |= "文件上传"

# 查询包含特定文件名的日志
{job="backend"} |= "file-service.log"

# 组合查询：错误日志 + 特定关键词
{job="backend"} |= "ERROR" |= "FileChannel"
```

#### 2.4 高级功能

##### Metrics 和 Logs 联动（论文中提到的核心功能）

1. **在 Spring Boot 监控大盘中发现问题**
   - 访问：http://localhost:3001/d/28e3358f-3fac-4321-804f-420e116de8a1/spring-boot-statistics
   - 看到 "HTTP 500 错误率" 突增

2. **框选时间范围**
   - 在 Grafana 大盘中，用鼠标框选错误突增的时间段（如 10:00:00 - 10:05:00）

3. **自动筛选日志**
   - 在 Logs 面板中，时间范围自动同步到框选的时间
   - 输入查询：`{job="backend"} |= "ERROR" [5m]`
   - 立即看到该时间段的所有错误日志，实现"秒级定位根因"

##### 设置告警规则

1. **创建 Alert 规则**
   - 进入 **Alerting** → **Alert Rules** → **New Alert Rule**

2. **设置告警条件**
   ```logql
   # 错误日志数量 > 10 条/分钟
   sum(count_over_time({job="backend"} |= "ERROR" [1m])) > 10
   ```

3. **配置通知渠道**
   - 邮件、钉钉、企业微信等

---

## 三、方式二：本地日志文件（开发环境推荐）

### 3.1 日志文件位置

根据项目配置，日志文件存储在：

```
backend/logs/
├── gateway-service.log      # 网关服务日志
├── knowledge-service.log    # 知识服务日志
├── file-service.log         # 文件服务日志
├── search-service.log       # 搜索服务日志
├── audit-service.log        # 审计服务日志
└── user-service.log         # 用户服务日志
```

### 3.2 查看日志命令

#### Windows PowerShell

```powershell
# 查看某个服务的实时日志（类似 tail -f）
Get-Content backend/logs/gateway-service.log -Wait -Tail 50

# 查看最后 100 行日志
Get-Content backend/logs/gateway-service.log -Tail 100

# 搜索包含 "ERROR" 的日志
Select-String -Path backend/logs/gateway-service.log -Pattern "ERROR"

# 搜索多个服务的错误日志
Select-String -Path backend/logs/*.log -Pattern "ERROR"
```

#### Linux/Mac

```bash
# 查看实时日志（推荐）
tail -f backend/logs/gateway-service.log

# 查看最后 100 行
tail -n 100 backend/logs/gateway-service.log

# 搜索包含 "ERROR" 的日志
grep -i "ERROR" backend/logs/gateway-service.log

# 搜索多个服务的错误日志
grep -r "ERROR" backend/logs/

# 搜索特定 TraceId（假设 TraceId 是 a1b2c3d4）
grep "a1b2c3d4" backend/logs/*.log

# 查看最近 1 小时的日志（需要日志时间格式支持）
grep "$(date -d '1 hour ago' '+%Y-%m-%d %H')" backend/logs/gateway-service.log
```

### 3.3 日志格式说明

根据论文中的 Logback 配置，日志格式如下：

```
2024-01-01 10:00:01.123 [http-nio-8080-exec-1] [a1b2c3d4] INFO  com.knowledge.gateway.controller.FileController - 接收上传请求: uploadId=xxx
```

格式解析：
- `2024-01-01 10:00:01.123`: 时间戳
- `[http-nio-8080-exec-1]`: 线程名
- `[a1b2c3d4]`: **TraceId**（用于链路追踪）
- `INFO`: 日志级别
- `com.knowledge.gateway.controller.FileController`: 类名
- `接收上传请求: uploadId=xxx`: 日志内容

### 3.4 快速排查命令组合

```bash
# 1. 查看最近错误（最后 50 行中包含 ERROR 的行）
tail -n 500 backend/logs/gateway-service.log | grep -i "ERROR" | tail -n 20

# 2. 查看特定时间段的日志（如 10:00-10:05）
grep "10:0[0-5]" backend/logs/gateway-service.log

# 3. 统计错误数量
grep -c "ERROR" backend/logs/gateway-service.log

# 4. 按 TraceId 追踪（跨多个服务）
grep "a1b2c3d4" backend/logs/*.log | sort

# 5. 查看异常堆栈（ERROR 及其后 20 行）
grep -A 20 "ERROR" backend/logs/gateway-service.log | head -n 100
```

---

## 四、方式三：Loki API 查询

### 4.1 适用场景

- 自动化脚本查询日志
- CI/CD 流水线中的日志检查
- 自定义监控工具集成

### 4.2 API 调用示例

#### 查询日志（HTTP GET）

```bash
# 查询所有服务的错误日志
curl "http://localhost:3100/loki/api/v1/query_range?query={job=\"backend\"}%20|=%20\"ERROR\"&limit=100"

# 查询特定服务的日志（最近 1 小时）
curl "http://localhost:3100/loki/api/v1/query_range?query={container=\"knowledge-gateway\"}&start=$(date -d '1 hour ago' +%s)000000000&end=$(date +%s)000000000"

# 查询包含 TraceId 的日志
curl "http://localhost:3100/loki/api/v1/query_range?query={job=\"backend\"}%20|=%20\"a1b2c3d4\"&limit=100"
```

#### 使用 PromQL 统计

```bash
# 统计错误日志数量（最近 5 分钟）
curl "http://localhost:3100/loki/api/v1/query_range?query=sum(count_over_time({job=\"backend\"}%20|=%20\"ERROR\"[5m]))"
```

---

## 五、常见问题排查流程

### 5.1 服务启动失败

**查看方式**：本地日志文件

```bash
# 查看启动日志
tail -f backend/logs/gateway-service.log

# 查看启动错误
grep -i "error\|exception\|failed" backend/logs/gateway-service.log | tail -n 50
```

### 5.2 接口返回 500 错误

**查看方式**：Grafana 或本地日志

```bash
# 方式1: 本地日志
grep "500\|ERROR\|Exception" backend/logs/gateway-service.log | tail -n 50

# 方式2: Grafana（推荐）
# 输入查询: {job="backend"} |= "ERROR" |= "500"
```

### 5.3 跨服务调用失败

**查看方式**：Grafana + TraceId

1. 获取 TraceId（从错误响应或前端日志）
2. 在 Grafana 中输入：`{job="backend"} |= "a1b2c3d4"`
3. 查看完整调用链路，定位失败的服务

### 5.4 性能问题（响应慢）

**查看方式**：Grafana Metrics + Logs 联动

1. 在 Grafana 大盘中发现响应时间突增
2. 框选时间范围
3. 在 Logs 面板中查询该时间段的日志：`{job="backend"} [5m]`
4. 查找慢查询、数据库连接等问题

### 5.5 内存溢出（OOM）

**查看方式**：本地日志文件（OOM 时 Grafana 可能无法访问）

```bash
# 查看 JVM 相关错误
grep -i "OutOfMemory\|OOM\|heap" backend/logs/*.log

# 查看 GC 日志（如果配置了）
grep -i "GC" backend/logs/*.log | tail -n 100
```

---

## 六、日志级别说明

根据项目配置，日志级别包括：

- **TRACE**: 最详细的调试信息（通常不启用）
- **DEBUG**: 调试信息（开发环境）
- **INFO**: 一般信息（正常流程）
- **WARN**: 警告信息（可能有问题但不影响运行）
- **ERROR**: 错误信息（需要关注）
- **FATAL**: 严重错误（服务可能无法继续运行）

**查看不同级别的日志**：

```logql
# Grafana 查询
{job="backend"} | json | level="ERROR"  # 只查询 ERROR 级别

# 本地文件
grep "ERROR" backend/logs/*.log
```

---

## 七、最佳实践

### 7.1 日常开发

✅ **使用本地日志文件**（方式二）
- 简单直接，无需启动额外服务
- 适合快速定位问题

### 7.2 生产环境

✅ **使用 Grafana**（方式一）
- 跨服务聚合，支持 TraceId 追踪
- 可视化好，易于定位根因

### 7.3 自动化监控

✅ **使用 Loki API**（方式三）
- CI/CD 流水线中的日志检查
- 自定义告警规则

### 7.4 TraceId 追踪（重要！）

**如何获取 TraceId**：
1. 前端错误提示中显示
2. HTTP 响应头：`X-Trace-Id: a1b2c3d4`
3. 错误日志中查找

**如何使用 TraceId**：
1. 在 Grafana 中输入：`{job="backend"} |= "a1b2c3d4"`
2. 查看完整请求链路，快速定位问题

---

## 八、总结

根据你的论文描述，推荐使用 **Grafana + Loki** 进行日志查看，因为：

1. ✅ **支持 TraceId 追踪**：跨服务链路追踪，快速定位问题
2. ✅ **Metrics 和 Logs 联动**：从指标发现问题，自动定位日志
3. ✅ **轻量级**：比 ELK Stack 资源占用少
4. ✅ **统一平台**：指标和日志在一个界面查看

但对于**快速开发调试**，直接查看本地日志文件更便捷。

---

## 九、快速参考

### Grafana 访问

- **URL**: http://localhost:3001
- **账号**: admin / Zhz050108

### 日志文件位置

```
backend/logs/
├── gateway-service.log
├── knowledge-service.log
├── file-service.log
├── search-service.log
├── audit-service.log
└── user-service.log
```

### 常用 Grafana 查询

```logql
# 查询所有错误
{job="backend"} |= "ERROR"

# 按 TraceId 追踪
{job="backend"} |= "a1b2c3d4"

# 查询特定服务
{container="knowledge-gateway"}

# 查询最近 5 分钟
{job="backend"} [5m]
```

### 常用本地命令

```bash
# 实时查看
tail -f backend/logs/gateway-service.log

# 搜索错误
grep -i "ERROR" backend/logs/*.log

# 按 TraceId 追踪
grep "a1b2c3d4" backend/logs/*.log | sort
```
